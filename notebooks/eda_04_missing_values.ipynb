{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de746699",
   "metadata": {},
   "source": [
    "### 04. Análisis y auditoría de valores faltantes\n",
    "\n",
    "Objetivos:\n",
    "- Cuantificar valores faltantes reales (dataset original).\n",
    "- Distinguir entre:\n",
    "  - Faltante genuino (dato que debería existir y no está).\n",
    "  - Valor *no aplicable* introducido por ingeniería (ej. `Evaluation_cp` es NaN porque hubo mate).\n",
    "- Verificar si existen patrones (correlación entre máscaras de faltantes).\n",
    "- Concluir sobre el mecanismo (MCAR / MAR / MNAR) y documentar si se requiere imputación.\n",
    "\n",
    "Contexto específico del dataset de ajedrez:\n",
    "- La columna original `Evaluation` se parseó a `Evaluation_cp`, `Evaluation_mate_sign`, `Evaluation_mate_in`.\n",
    "- Cuando hay mate, `Evaluation_cp` es NaN por diseño (no es realmente un faltante).\n",
    "- Cuando NO hay mate, `Evaluation_mate_in` es NaN (también \"no aplica\").\n",
    "- Por lo tanto la gran mayoría (o totalidad) de los NaN provienen de reglas de transformación.\n",
    "\n",
    "Criterios de clasificación en este notebook:\n",
    "- `real_missing`: NaN en columnas originales (si existieran).\n",
    "- `engineered_na`: NaN proveniente de columnas derivadas con sufijos `_cp`, `_mate_sign`, `_mate_in`.\n",
    "- `none`: sin valores NaN.\n",
    "- `mixed_or_derived`: otros casos residuales (si aparecieran nuevas transformaciones).\n",
    "\n",
    ".> Si no hay faltantes genuinos, se documenta claramente para la trazabilidad del pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b544240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] No se pudo importar functions.functions directamente -> ajustando sys.path\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] No se pudo importar functions.functions directamente -> ajustando sys.path\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mReusando DataFrame existente:\u001b[39m\u001b[33m'\u001b[39m, df.shape)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     df = \u001b[43mload_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_chess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mDataFrame cargado con load_csv:\u001b[39m\u001b[33m'\u001b[39m, df.shape)\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Definir columnas originales (antes de ingeniería) si no existen\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USUARIO\\Documents\\Code\\stocksalmon\\functions\\functions.py:21\u001b[39m, in \u001b[36mload_csv\u001b[39m\u001b[34m(path, usecols, dtypes, nrows)\u001b[39m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo existe: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# evita inferencias parciales\u001b[39;49;00m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_bad_lines\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwarn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# avisa si hay líneas corruptas\u001b[39;49;00m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mPD_KW\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# usa backend pyarrow si está disponible\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     30\u001b[39m     df = pd.read_csv(\n\u001b[32m     31\u001b[39m         path,\n\u001b[32m     32\u001b[39m         usecols=usecols,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m         on_bad_lines=\u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     36\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USUARIO\\Documents\\Code\\stocksalmon-venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USUARIO\\Documents\\Code\\stocksalmon-venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USUARIO\\Documents\\Code\\stocksalmon-venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USUARIO\\Documents\\Code\\stocksalmon-venv\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:239\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._first_chunk:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:820\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:921\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:1083\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._convert_column_data\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:1474\u001b[39m, in \u001b[36mpandas._libs.parsers._maybe_upcast\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USUARIO\\Documents\\Code\\stocksalmon-venv\\Lib\\site-packages\\pandas\\core\\arrays\\string_.py:158\u001b[39m, in \u001b[36mStringDtype.__init__\u001b[39m\u001b[34m(self, storage, na_value)\u001b[39m\n\u001b[32m    156\u001b[39m             storage = \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     storage = \u001b[43mget_option\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmode.string_storage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m storage == \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    160\u001b[39m         storage = \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USUARIO\\Documents\\Code\\stocksalmon-venv\\Lib\\site-packages\\pandas\\_config\\config.py:273\u001b[39m, in \u001b[36mCallableDynamicDoc.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m.__doc_tmpl__ = doc_tmpl\n\u001b[32m    271\u001b[39m     \u001b[38;5;28mself\u001b[39m.\u001b[34m__func__\u001b[39m = func\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwds) -> T:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__func__\u001b[39m(*args, **kwds)\n\u001b[32m    276\u001b[39m \u001b[38;5;66;03m# error: Signature of \"__doc__\" incompatible with supertype \"object\"\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Carga directa (versión copiada)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = Path('../data/raw')\n",
    "CHESS_PATH = DATA_DIR / 'chessData.csv'\n",
    "\n",
    "def load_chess(nrows=None, usecols=None):\n",
    "    \"\"\"Carga chessData.csv con backend pyarrow si disponible.\n",
    "    - nrows: permite carga parcial para pruebas rápidas.\n",
    "    - usecols: para limitar columnas.\n",
    "    \"\"\"\n",
    "    read_kw = dict(low_memory=False, on_bad_lines='warn')\n",
    "    try:\n",
    "        # pandas >= 2 admite dtype_backend='pyarrow'\n",
    "        return pd.read_csv(CHESS_PATH, dtype_backend='pyarrow', nrows=nrows, usecols=usecols, **read_kw)\n",
    "    except TypeError:\n",
    "        return pd.read_csv(CHESS_PATH, nrows=nrows, usecols=usecols, **read_kw)\n",
    "\n",
    "df = load_chess()\n",
    "print(f'Filas: {len(df):,}  | Columnas: {len(df.columns)}')\n",
    "print('Columnas del df:', list(df.columns[:15]))\n",
    "\n",
    "# Definir columnas originales si no existen todavía\n",
    "if 'ORIG_COLUMNS' not in globals():\n",
    "    ORIG_COLUMNS = [c for c in df.columns if not c.endswith(('_cp','_mate_sign','_mate_in'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a13c80b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Guardar columnas originales justo después de cargar (si no se guardó antes)\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mORIG_COLUMNS\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     ORIG_COLUMNS = [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m.columns \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m c.endswith((\u001b[33m'\u001b[39m\u001b[33m_cp\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m_mate_sign\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m_mate_in\u001b[39m\u001b[33m'\u001b[39m))]\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34manalyze_missing_values\u001b[39m(\n\u001b[32m     24\u001b[39m     df: pd.DataFrame,\n\u001b[32m     25\u001b[39m     original_cols=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     26\u001b[39m     engineered_suffixes=(\u001b[33m'\u001b[39m\u001b[33m_cp\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m_mate_sign\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m_mate_in\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     27\u001b[39m     show_plot=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     28\u001b[39m ):\n\u001b[32m     29\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    Analiza valores faltantes distinguiendo:\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03m      - missing_real: NaN en columnas originales\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[33;03m      - engineered_na: NaN en columnas derivadas por diseño (no aplica)\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# --- 04. Análisis y auditoría de valores faltantes --------------------------------\n",
    "#\n",
    "# Objetivos:\n",
    "#  - Cuantificar valores faltantes reales.\n",
    "#  - Separar NaN introducidos por ingeniería (mate_in, mate_sign, *_cp cuando hay mate).\n",
    "#  - Evaluar patrones (si los hubiera) y comentar MCAR / MAR / MNAR.\n",
    "#  - Concluir si se requiere imputación (en este dataset no).\n",
    "#\n",
    "# Notas:\n",
    "#  * NaN en Evaluation_cp cuando hay mate -> NO es \"dato perdido\"; significa \"no aplica (mate)\".\n",
    "#  * Mate_in NaN cuando no hay mate -> también \"no aplica\".\n",
    "#  * Solo consideraremos \"faltante real\" si la columna original tenía NaN antes de generar columnas derivadas.\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Guardar columnas originales justo después de cargar (si no se guardó antes)\n",
    "if 'ORIG_COLUMNS' not in globals():\n",
    "    ORIG_COLUMNS = [c for c in df.columns if not c.endswith(('_cp','_mate_sign','_mate_in'))]\n",
    "\n",
    "def analyze_missing_values(\n",
    "    df: pd.DataFrame,\n",
    "    original_cols=None,\n",
    "    engineered_suffixes=('_cp','_mate_sign','_mate_in'),\n",
    "    show_plot=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Analiza valores faltantes distinguiendo:\n",
    "      - missing_real: NaN en columnas originales\n",
    "      - engineered_na: NaN en columnas derivadas por diseño (no aplica)\n",
    "    \"\"\"\n",
    "    original_cols = original_cols or ORIG_COLUMNS\n",
    "    \n",
    "    n = len(df)\n",
    "    base = pd.DataFrame(index=df.columns)\n",
    "    base['total'] = n\n",
    "    base['missing_count'] = df.isna().sum()\n",
    "    base['missing_pct'] = base['missing_count'] / n * 100\n",
    "    base['dtype'] = df.dtypes.astype(str)\n",
    "    \n",
    "    # Clasificación simple\n",
    "    def classify(col, miss_cnt):\n",
    "        if miss_cnt == 0:\n",
    "            return 'none'\n",
    "        if col in original_cols:\n",
    "            return 'real_missing'\n",
    "        if col.endswith(engineered_suffixes):\n",
    "            return 'engineered_na'\n",
    "        return 'mixed_or_derived'\n",
    "    \n",
    "    base['missing_type'] = [\n",
    "        classify(c, base.loc[c,'missing_count']) for c in base.index\n",
    "    ]\n",
    "    \n",
    "    # Separar verdaderos faltantes (solo columnas originales con NaN)\n",
    "    real_missing = base[(base.missing_type=='real_missing') & (base.missing_count>0)]\n",
    "    \n",
    "    if show_plot and len(real_missing) > 0:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14,5))\n",
    "        rm_sorted = real_missing.sort_values('missing_pct', ascending=False)\n",
    "        axes[0].bar(rm_sorted.index, rm_sorted['missing_pct'], color='coral')\n",
    "        axes[0].set_ylabel('% faltante')\n",
    "        axes[0].set_title('Porcentaje de valores faltantes (reales)')\n",
    "        axes[0].tick_params(axis='x', rotation=90)\n",
    "        axes[0].axhline(5, ls='--', color='red', label='Umbral 5%')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        # Mapa de correlación de patrones (solo columnas con faltantes reales)\n",
    "        miss_pattern = df[rm_sorted.index].isna().astype(int)\n",
    "        if miss_pattern.shape[1] >= 2:\n",
    "            sns.heatmap(miss_pattern.corr(), annot=True, fmt='.2f',\n",
    "                        cmap='coolwarm', vmin=-1, vmax=1, ax=axes[1])\n",
    "            axes[1].set_title('Correlación patrones de faltantes')\n",
    "        else:\n",
    "            axes[1].axis('off')\n",
    "            axes[1].text(0.5,0.5,'Sólo 1 columna con faltantes reales', ha='center')\n",
    "        plt.tight_layout()\n",
    "    elif show_plot:\n",
    "        print(\"✅ No hay valores faltantes reales en columnas originales.\")\n",
    "    \n",
    "    return base.sort_values('missing_pct', ascending=False)\n",
    "\n",
    "missing_report = analyze_missing_values(df)\n",
    "\n",
    "display(\n",
    "    missing_report[['missing_count','missing_pct','missing_type','dtype']]\n",
    "      .head(25)\n",
    "      .style.format({'missing_pct':'{:.2f}'})\n",
    ")\n",
    "\n",
    "# Resumen textual\n",
    "total_cols = len(missing_report)\n",
    "real_cols_with_missing = (missing_report.missing_type=='real_missing') & (missing_report.missing_count>0)\n",
    "n_real_missing_cols = real_cols_with_missing.sum()\n",
    "max_pct = missing_report.loc[real_cols_with_missing,'missing_pct'].max() if n_real_missing_cols else 0\n",
    "\n",
    "print(\"\\n--- Conclusión de auditoría ---\")\n",
    "if n_real_missing_cols == 0:\n",
    "    print(\"No se detectaron valores faltantes genuinos en las columnas originales.\")\n",
    "    print(\"Los NaN presentes pertenecen a columnas derivadas (mate / no aplica).\")\n",
    "    print(\"No se requiere imputación. Clasificación: ausencia de patrones MCAR/MAR/MNAR porque no hay faltantes reales.\")\n",
    "else:\n",
    "    print(f\"{n_real_missing_cols} columnas originales con faltantes. Máximo porcentaje: {max_pct:.2f}%.\")\n",
    "    print(\"Inspeccionar si son MCAR (aleatorios), MAR (dependen de otras vars) o MNAR (dependen de su propio valor).\")\n",
    "    print(\"Aplicar estrategia de imputación adecuada (media/mediana/modelo) sólo si son relevantes para el modelado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8be72",
   "metadata": {},
   "source": [
    "#### Conclusión\n",
    "- No se identificaron valores faltantes genuinos en las columnas originales del dataset de posiciones de ajedrez.\n",
    "- Los NaN observados pertenecen a columnas derivadas (`*_cp`, `*_mate_in`) y representan un estado *no aplicable* (mate presente o ausente).\n",
    "- No procede imputación (evita introducir sesgo artificial).\n",
    "- Mecanismo: ausencia de faltantes reales ⇒ no aplica clasificación MCAR/MAR/MNAR.\n",
    "\n",
    "**Siguiente paso:** continuar con ingeniería de variables / creación de etiqueta de ventaja para el modelo de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1161d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización opcional: barras comparando tipos de NA\n",
    "def plot_missing_type_counts(report):\n",
    "    counts = report['missing_type'].value_counts()\n",
    "    if counts.empty:\n",
    "        print('Sin categorías de faltantes para graficar.')\n",
    "        return\n",
    "    ax = counts.plot(kind='bar', color=['#4c72b0','#dd8452','#55a868','#c44e52'])\n",
    "    ax.set_ylabel('Número de columnas')\n",
    "    ax.set_title('Conteo de columnas por tipo de faltante')\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(int(p.get_height()), (p.get_x()+p.get_width()/2, p.get_height()),\n",
    "                    ha='center', va='bottom')\n",
    "    plt.show()\n",
    "\n",
    "plot_missing_type_counts(missing_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca05317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado localmente en este notebook: (12958035, 2)\n",
      "Columnas (primeras 15): ['FEN', 'Evaluation']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEN</th>\n",
       "      <th>Evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR ...</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rnbqkbnr/pppp1ppp/4p3/8/4P3/8/PPPP1PPP/RNBQKBN...</td>\n",
       "      <td>+56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rnbqkbnr/pppp1ppp/4p3/8/3PP3/8/PPP2PPP/RNBQKBN...</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 FEN Evaluation\n",
       "0  rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR ...        -10\n",
       "1  rnbqkbnr/pppp1ppp/4p3/8/4P3/8/PPPP1PPP/RNBQKBN...        +56\n",
       "2  rnbqkbnr/pppp1ppp/4p3/8/3PP3/8/PPP2PPP/RNBQKBN...         -9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga ligera del dataset si 'df' no está en memoria (permite ejecutar este notebook de forma independiente)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if 'df' not in globals():\n",
    "    DATA_DIR = Path('../data/raw')\n",
    "    CHESS_PATH = DATA_DIR / 'chessData.csv'\n",
    "    df = pd.read_csv(CHESS_PATH, low_memory=False)\n",
    "    print('Dataset cargado localmente en este notebook:', df.shape)\n",
    "else:\n",
    "    print('Usando DataFrame existente en memoria:', df.shape)\n",
    "\n",
    "# Mostrar primeras columnas para referencia rápida\n",
    "print('Columnas (primeras 15):', list(df.columns[:15]))\n",
    "df.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stocksalmon-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
